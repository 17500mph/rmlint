rmlint is a command line tool to remove various sort of unused files form a Unix filesystem. 
It comes without any extra depencies, and is build to handle even large filesystems quite fast.  
It is written in pure C (conforming the ISOC99 Standard), and comes with as size of 32K  

At time of writing (28.9.2010) this is still beta software and you should choose on of http://en.wikipedia.org/wiki/Fdupes those. 
It nevertheless is already usable and owns alternatives in terms of speed :-) (duff: 90sec, rmlint: 0.58sec) 

DISCLAIMER: 
THERE IS NO WARRANTY THAT THIS SOFTWARE WON'T KILL YOUR FILES, NOR THAT IT KILLS YOUR KITTEN, BURNS YOUR HOUSE, OR WHATSOEVER. 
IT WAS written carefully and in the hope it'll will be useful for some messy users. 


HELP: 
------------
- This Readme.
- rmlint -h 
- man rmlint  

FEATURES:
--------
- Can be aborted at any time. Will display all finds then. (or abort if user presses CTRL-C once more) 
- Fast. Handles 60GB of data in under 1 second, 
- Regex filter. 
- Colorful! :-) (can be compiled without colors support) 
- Can handle huge amount of files. 
- Handles the files the way you want: 
   + replace double file by a symboliclink, (-m link)  
   + Removes the file without asking you. (-m noask) 
   + Simply list all files without doing anything dangerous. (-m list) 
   + It executes a user specified commando for each file (-m cmd) 
   + It asks you for each file what you want. (-m ask)
   * In all cases a log called rmlint.sh is written. (So you can exec it after having a closer look) 
- Minimum of I/O, focuses on CPU usage. 
- It has some basic "API" (Well.. :-)) 


HOW DOES THIS WEIRD THING WORK: 
-------------------------------
In contrast to plenty other programs doing the same job, rmlint tries to reduce reading data from the harddrive. 
Therefore it goes recursively through all directories and pushes all files back to a list. 
This list is filtered by removing files with a unique filesize. If two files have the same size, 
it'll build a short fingerprint of the files and compare them. 
From all files that passed the filter a full md5-checksum is build, and compared afterwards. 
The resulting files can be considered to be duplicates. 


A NOTE ABOUT FALSE POSITIVES: 
-----------------------------
False Positves are actuallly possible, but very unlikely. 
A so-called collision has about a probability (under best conditions) of 1/(255^16) + 
They would need to have the same size to be marked as duplicate.  
=> Very unlikely, but possible (dirty, little word) 
Nevertheless there is/will be a --verify option that double checks by byte-by-byte comparasion.

OPTIONS: 
-------
More. to. come.

FAQ: 
----

Q: Why does the last bit of the "Building database"-step takes so long? 
A: The list where the suspected files are stored is sorted by size. Therefore at the end the largest files have to built a checksum.  
   You can see the size in "Building database.. 85.9% [16315/19004] - [ 0 ]  - [31842 Bytes]", here as 31842 Byte. 

